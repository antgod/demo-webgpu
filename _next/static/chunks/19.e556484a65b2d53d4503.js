(window.webpackJsonp_N_E=window.webpackJsonp_N_E||[]).push([[19],{f7eb:function(e,n,t){"use strict";t.r(n),function(e,r){var a=t("o0o1"),i=t.n(a),o=t("HaE+"),s=t("IOcx"),c=t("8i9l"),u=t("1uVF"),m=t("8N3a"),d=t("xZX2"),f=function(){var e=Object(o.a)(i.a.mark((function e(n){var r,a,o,c,f,l,p,g,x,b,h,v,w,T,P,S,M,E,B,U,y;return i.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:return y=function(){if(r.current){var e=U();o.queue.writeBuffer(h,0,e.buffer,e.byteOffset,e.byteLength),M.colorAttachments[0].view=c.getCurrentTexture().createView();var n=o.createCommandEncoder(),t=n.beginRenderPass(M);t.setPipeline(x),t.setBindGroup(0,S),t.setVertexBuffer(0,g),t.draw(u.d,1,0,0),t.endPass(),o.queue.submit([n.finish()]),requestAnimationFrame(y)}},U=function(){var e=s.a.create();s.a.translate(e,e,s.b.fromValues(0,0,-4));var n=Date.now()/1e3;s.a.rotate(e,e,1,s.b.fromValues(Math.sin(n),Math.cos(n),0));var t=s.a.create();return s.a.multiply(t,B,e),t},r=n.canvasRef,e.next=5,navigator.gpu.requestAdapter();case 5:return a=e.sent,e.next=8,a.requestDevice();case 8:if(o=e.sent,null!==r.current){e.next=11;break}return e.abrupt("return");case 11:return c=r.current.getContext("webgpu"),f=window.devicePixelRatio||1,l=[r.current.clientWidth*f,r.current.clientHeight*f],p=c.getPreferredFormat(a),c.configure({device:o,format:p,size:l}),g=o.createBuffer({size:u.c.byteLength,usage:GPUBufferUsage.VERTEX,mappedAtCreation:!0}),new Float32Array(g.getMappedRange()).set(u.c),g.unmap(),x=o.createRenderPipeline({vertex:{module:o.createShaderModule({code:m.a}),entryPoint:"main",buffers:[{arrayStride:u.e,attributes:[{shaderLocation:0,offset:u.a,format:"float32x4"},{shaderLocation:1,offset:u.b,format:"float32x2"}]}]},fragment:{module:o.createShaderModule({code:d.a}),entryPoint:"main",targets:[{format:p}]},primitive:{topology:"triangle-list",cullMode:"back"},depthStencil:{depthWriteEnabled:!0,depthCompare:"less",format:"depth24plus"}}),b=o.createTexture({size:l,format:"depth24plus",usage:GPUTextureUsage.RENDER_ATTACHMENT}),64,h=o.createBuffer({size:64,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),(w=document.createElement("img")).src=t("neuz"),e.next=27,w.decode();case 27:return e.next=29,createImageBitmap(w);case 29:T=e.sent,v=o.createTexture({size:[T.width,T.height,1],format:"rgba8unorm",usage:GPUTextureUsage.TEXTURE_BINDING|GPUTextureUsage.COPY_DST|GPUTextureUsage.RENDER_ATTACHMENT}),o.queue.copyExternalImageToTexture({source:T},{texture:v},[T.width,T.height]),P=o.createSampler({magFilter:"linear",minFilter:"linear"}),S=o.createBindGroup({layout:x.getBindGroupLayout(0),entries:[{binding:0,resource:{buffer:h}},{binding:1,resource:P},{binding:2,resource:v.createView()}]}),M={colorAttachments:[{view:void 0,loadValue:{r:.5,g:.5,b:.5,a:1},storeOp:"store"}],depthStencilAttachment:{view:b.createView(),depthLoadValue:1,depthStoreOp:"store",stencilLoadValue:0,stencilStoreOp:"store"}},E=l[0]/l[1],B=s.a.create(),s.a.perspective(B,2*Math.PI/5,E,1,100),requestAnimationFrame(y);case 39:case"end":return e.stop()}}),e)})));return function(n){return e.apply(this,arguments)}}();n.default=function(){return Object(c.a)({name:"Textured Cube",description:"This example shows how to bind and sample textures.",init:f,sources:[{name:e.substr(r.length+1),contents:"import { mat4, vec3 } from 'gl-matrix';\nimport { makeSample, SampleInit } from '../../components/SampleLayout';\n\nimport {\n  cubeVertexArray,\n  cubeVertexSize,\n  cubeUVOffset,\n  cubePositionOffset,\n  cubeVertexCount,\n} from '../../meshes/cube';\n\nimport basicVertWGSL from '../../shaders/basic.vert.wgsl';\nimport sampleTextureMixColorWGSL from './sampleTextureMixColor.frag.wgsl';\n\nconst init: SampleInit = async ({ canvasRef }) => {\n  const adapter = await navigator.gpu.requestAdapter();\n  const device = await adapter.requestDevice();\n\n  if (canvasRef.current === null) return;\n  const context = canvasRef.current.getContext('webgpu');\n\n  const devicePixelRatio = window.devicePixelRatio || 1;\n  const presentationSize = [\n    canvasRef.current.clientWidth * devicePixelRatio,\n    canvasRef.current.clientHeight * devicePixelRatio,\n  ];\n  const presentationFormat = context.getPreferredFormat(adapter);\n\n  context.configure({\n    device,\n    format: presentationFormat,\n    size: presentationSize,\n  });\n\n  // Create a vertex buffer from the cube data.\n  const verticesBuffer = device.createBuffer({\n    size: cubeVertexArray.byteLength,\n    usage: GPUBufferUsage.VERTEX,\n    mappedAtCreation: true,\n  });\n  new Float32Array(verticesBuffer.getMappedRange()).set(cubeVertexArray);\n  verticesBuffer.unmap();\n\n  const pipeline = device.createRenderPipeline({\n    vertex: {\n      module: device.createShaderModule({\n        code: basicVertWGSL,\n      }),\n      entryPoint: 'main',\n      buffers: [\n        {\n          arrayStride: cubeVertexSize,\n          attributes: [\n            {\n              // position\n              shaderLocation: 0,\n              offset: cubePositionOffset,\n              format: 'float32x4',\n            },\n            {\n              // uv\n              shaderLocation: 1,\n              offset: cubeUVOffset,\n              format: 'float32x2',\n            },\n          ],\n        },\n      ],\n    },\n    fragment: {\n      module: device.createShaderModule({\n        code: sampleTextureMixColorWGSL,\n      }),\n      entryPoint: 'main',\n      targets: [\n        {\n          format: presentationFormat,\n        },\n      ],\n    },\n    primitive: {\n      topology: 'triangle-list',\n\n      // Backface culling since the cube is solid piece of geometry.\n      // Faces pointing away from the camera will be occluded by faces\n      // pointing toward the camera.\n      cullMode: 'back',\n    },\n\n    // Enable depth testing so that the fragment closest to the camera\n    // is rendered in front.\n    depthStencil: {\n      depthWriteEnabled: true,\n      depthCompare: 'less',\n      format: 'depth24plus',\n    },\n  });\n\n  const depthTexture = device.createTexture({\n    size: presentationSize,\n    format: 'depth24plus',\n    usage: GPUTextureUsage.RENDER_ATTACHMENT,\n  });\n\n  const uniformBufferSize = 4 * 16; // 4x4 matrix\n  const uniformBuffer = device.createBuffer({\n    size: uniformBufferSize,\n    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n  });\n\n  // Fetch the image and upload it into a GPUTexture.\n  let cubeTexture: GPUTexture;\n  {\n    const img = document.createElement('img');\n    img.src = require('../../../assets/img/Di-3d.png');\n    await img.decode();\n    const imageBitmap = await createImageBitmap(img);\n\n    cubeTexture = device.createTexture({\n      size: [imageBitmap.width, imageBitmap.height, 1],\n      format: 'rgba8unorm',\n      usage:\n        GPUTextureUsage.TEXTURE_BINDING |\n        GPUTextureUsage.COPY_DST |\n        GPUTextureUsage.RENDER_ATTACHMENT,\n    });\n    device.queue.copyExternalImageToTexture(\n      { source: imageBitmap },\n      { texture: cubeTexture },\n      [imageBitmap.width, imageBitmap.height]\n    );\n  }\n\n  // Create a sampler with linear filtering for smooth interpolation.\n  const sampler = device.createSampler({\n    magFilter: 'linear',\n    minFilter: 'linear',\n  });\n\n  const uniformBindGroup = device.createBindGroup({\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      {\n        binding: 0,\n        resource: {\n          buffer: uniformBuffer,\n        },\n      },\n      {\n        binding: 1,\n        resource: sampler,\n      },\n      {\n        binding: 2,\n        resource: cubeTexture.createView(),\n      },\n    ],\n  });\n\n  const renderPassDescriptor: GPURenderPassDescriptor = {\n    colorAttachments: [\n      {\n        view: undefined, // Assigned later\n\n        loadValue: { r: 0.5, g: 0.5, b: 0.5, a: 1.0 },\n        storeOp: 'store',\n      },\n    ],\n    depthStencilAttachment: {\n      view: depthTexture.createView(),\n\n      depthLoadValue: 1.0,\n      depthStoreOp: 'store',\n      stencilLoadValue: 0,\n      stencilStoreOp: 'store',\n    },\n  };\n\n  const aspect = presentationSize[0] / presentationSize[1];\n  const projectionMatrix = mat4.create();\n  mat4.perspective(projectionMatrix, (2 * Math.PI) / 5, aspect, 1, 100.0);\n\n  function getTransformationMatrix() {\n    const viewMatrix = mat4.create();\n    mat4.translate(viewMatrix, viewMatrix, vec3.fromValues(0, 0, -4));\n    const now = Date.now() / 1000;\n    mat4.rotate(\n      viewMatrix,\n      viewMatrix,\n      1,\n      vec3.fromValues(Math.sin(now), Math.cos(now), 0)\n    );\n\n    const modelViewProjectionMatrix = mat4.create();\n    mat4.multiply(modelViewProjectionMatrix, projectionMatrix, viewMatrix);\n\n    return modelViewProjectionMatrix as Float32Array;\n  }\n\n  function frame() {\n    // Sample is no longer the active page.\n    if (!canvasRef.current) return;\n\n    const transformationMatrix = getTransformationMatrix();\n    device.queue.writeBuffer(\n      uniformBuffer,\n      0,\n      transformationMatrix.buffer,\n      transformationMatrix.byteOffset,\n      transformationMatrix.byteLength\n    );\n    renderPassDescriptor.colorAttachments[0].view = context\n      .getCurrentTexture()\n      .createView();\n\n    const commandEncoder = device.createCommandEncoder();\n    const passEncoder = commandEncoder.beginRenderPass(renderPassDescriptor);\n    passEncoder.setPipeline(pipeline);\n    passEncoder.setBindGroup(0, uniformBindGroup);\n    passEncoder.setVertexBuffer(0, verticesBuffer);\n    passEncoder.draw(cubeVertexCount, 1, 0, 0);\n    passEncoder.endPass();\n    device.queue.submit([commandEncoder.finish()]);\n\n    requestAnimationFrame(frame);\n  }\n  requestAnimationFrame(frame);\n};\n\nconst TexturedCube: () => JSX.Element = () =>\n  makeSample({\n    name: 'Textured Cube',\n    description: 'This example shows how to bind and sample textures.',\n    init,\n    sources: [\n      {\n        name: __filename.substr(__dirname.length + 1),\n        contents: __SOURCE__,\n      },\n      {\n        name: '../../shaders/basic.vert.wgsl',\n        contents: basicVertWGSL,\n        editable: true,\n      },\n      {\n        name: './sampleTextureMixColor.frag.wgsl',\n        contents: sampleTextureMixColorWGSL,\n        editable: true,\n      },\n      {\n        name: '../../meshes/cube.ts',\n        // eslint-disable-next-line @typescript-eslint/no-var-requires\n        contents: require('!!raw-loader!../../meshes/cube.ts').default,\n      },\n    ],\n    filename: __filename,\n  });\n\nexport default TexturedCube;\n"},{name:"../../shaders/basic.vert.wgsl",contents:m.a,editable:!0},{name:"./sampleTextureMixColor.frag.wgsl",contents:d.a,editable:!0},{name:"../../meshes/cube.ts",contents:t("MYnn").default}],filename:e})}}.call(this,"src/sample/texturedCube/main.ts","src/sample/texturedCube")},neuz:function(e,n){e.exports="/webgpu-samples/_next/static/e04932ba9c013b60ddb249577c386914.png"},xZX2:function(e,n,t){"use strict";n.a="[[group(0), binding(1)]] var mySampler: sampler;\n[[group(0), binding(2)]] var myTexture: texture_2d<f32>;\n\n[[stage(fragment)]]\nfn main([[location(0)]] fragUV: vec2<f32>,\n        [[location(1)]] fragPosition: vec4<f32>) -> [[location(0)]] vec4<f32> {\n  return textureSample(myTexture, mySampler, fragUV) * fragPosition;\n}\n"}}]);